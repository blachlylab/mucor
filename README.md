Contents
========
[Introduction](#introduction)

[Requirements](#requirements)

[Installation](#installation)

[Setup and Operation](#setup-and-operation)

[Known Issues](#known-issues)

[Bug Reports and Issue Tracking](#bug-reports-and-issue-tracking)

[Contact](#contact)


Introduction
============

Vaggregate is software to aggregate variant information sourced from multiple VCF files (and some others, see below) into a variety of summary files with varying levels of detail and statistics. The outputs range from high-level summaries to full, detailed reports in text and Microsoft Excel formats. The intended audience is both biologists and bioinformaticians.

Requirements
============

Python modules
--------------

The following modules are required:

* numpy (http://www.numpy.org/)
* pandas (http://pandas.pydata.org/)
* HTSeq (http://www-huber.embl.de/HTSeq/)

The following modules are optional:

* pytabix (https://github.com/slowkow/pytabix)
* XlsxWriter (https://github.com/jmcnamara/XlsxWriter)
* xlwt (https://pypi.python.org/pypi/xlwt)

Additional tools
----------------

* bgzip and Tabix (optional, see _Databases_, below; https://github.com/samtools/htslib)

Annotation
----------

Vaggregate requires a reference annotation file (in GTF or GFF3 format) for feature definition. Contig (chromosome) names must match between the input VCF and reference annotation file; for example, for _Homo sapiens_, UCSC uses the form **chr17** while Ensembl uses the form **17**. 

Protip: If your human data are aligned and variants called with _chr_ style contig names but you wish to use Ensembl genes, you can try the GENCODE annotation which contains most Ensembl genes but using _chr_ style contig numbering.

Databases
---------

Vaggregate can _optionally_ check variants against any number of supplied databases and report presence (including identifier) or absence in the database. Common choices would be one or more releases of dbSNP (e.g., dbSNP 137 and latest dbSNP; dbSNP clinvar and dbSNP all), 1000 Genomes, NHLBI 6500 Exomes, or COSMIC. Users may also supply their own custom databases.

Databses must meet the following requirements:
* Conform to VCF standard format
* be compressed with bgzip (_not_ gzip; see below)
* be indexed with tabix (see below). 

bgzip and tabix provide massive speedups looking up variants in these external files. The database lookup feature is not available if files are not correctly bgzipped or tabix indexed, or if the Pytabix module is not installed. `bgzip` and `tabix` are available as part of `htslib` (https://github.com/samtools/htslib)

### Database preparation

Beginning with an example VCF `dbSNP.vcf`, execute the following:

```
$ bgzip dbSNP.vcf
$ tabix -p vcf dbSNP.vcf.gz
```

Note that bgzipped files can be treated as regular .gz files by other tools.


Variant call data
-----------------

These data are the data that you wish to aggregate and summarize. In theory, Vaggregate will work with any well-formed generic VCF, but it has been tested with and contains specific code to handle VCF files generated by the following tools:

* snpEff
* Ion Torrent PGM (default machine output)
* Illumina Miseq (default machine output)
* GATK
* GATK SomaticIndelDetector
* GATK HaplotypeCaller
* MuTect
* VarScan
* FreeBayes
* Samtools

In addition, Vaggregate can read the more detailed .out files produced by MuTect.


Installation
============

git clone https://github.com/blachlylab/vaggregate.git

Setup and Operation
===================

Overview
--------
Running Vaggregate to aggregate and summarize variants is a two step process:

1. Project setup / configuration
    * `vagg_config.py` creates a JSON config file

2. Variant Aggregation!
    * `vagg.py` 

Project setup
-------------

### Configuration with `vagg_config.py`

The configuration step is completed using the provided `vagg_config.py` utility. It accepts the following command line arguments and creates a JSON file that will be passed to the main Vaggregate script. 

`-ex, --example`        Print a valid, example JSON config file and exit.
Function that will write a template of the JSON config. It can be edited manually and supplied to vaggregate. 

`-g GFF, --gff GFF`
Reference annotation GFF/GTF for feature binning. Required

`-f FEATURETYPE, --featuretype FEATURETYPE`
Feature type into which to bin. Gencode GTF example: gene_name, gene_id, transcript_name, transcript_id, etc. Required

`-db DATABASES, --databases DATABASES`
Colon delimited name and path to variant database in bgzipped VCF format. Can be declared >= 0 times. Ex: -db name1:/full/user/path/name1.vcf.gz. Optional

`-s SAMPLES, --samples SAMPLES`
Text file containing sample names. One sample per line. `vagg_config.py` attempts to guess which files belong with which sample IDs using globbing (wildcard filename matching). This means that the auto-configuration may be incorrect if any sample names are contained within another sample name. Ex: U-23 and U-238. U-23 would erroneously identify U-238 files, requiring manual modification of the JSON file. Sample IDs U-023 and U-238 would not exhibit this problem. Required

`-d PROJECT_DIRECTORY, --project_directory PROJECT_DIRECTORY`
Working/project directory, in which to find variant call files to aggregate. Variant calls can be in the provided directory, or any of its subdirectories. Default: current working directory

`-vcff VCF_FILTERS, --vcf_filters VCF_FILTERS`
Comma separated list of VCF filters to allow. Default: PASS

`-a ARCHIVE_DIRECTORY, --archive_directory ARCHIVE_DIRECTORY`
Specify directory in which to read/write archived annotations. This step will significantly speed up future runs that use the same annotation and feature type, even if the sample data changes. Undefined will prevent using the annotation archive features. Optional

`-r REGIONS, --regions REGIONS`
Comma separated list of bed regions and/or bed files by which to limit output. Bed regions can be specific positions, or entire chromosomes. Ex: chr1:10230-10240,chr2,my_regions.bed. Optional

`-u, --union`
Join all items with same ID for feature_type (specified by -f) into a single, continuous bin. For example, if you want intronic variants counted with a gene, use this option. WARNING, this will lead to spurious results for features that are duplicated on the same contig. When feature names are identical, the bin will range from the beginning of the first instance to the end of the last, even if they are several megabases apart. Refer to the documentation for a resolution using 'detect_union_bin_errors.py.' Optional.


`-jco JSON_CONFIG_OUTPUT, --json_config_output JSON_CONFIG_OUTPUT`
Name of JSON configuration output file. This is the configuration file fed into Vaggregate. Required

`-outd OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY`
Name of directory in which to write Vaggregate output. Required

`-outt OUTPUT_TYPE, --output_type OUTPUT_TYPE`
Comma separated list of desired output types. Options include: counts, txt, longtxt, xls, longxls, bed, featXsamp, featmutXsamp, all. Default: counts,txt
(See the detailed description of [Output File Formats](#output-file-formats), below)

Example:

    python ./vagg_config.py -g ~/references/human/gencode/gencode.v19.annotation.gtf -f gene_name -s samples.txt -a ./fast -u -jco vaggregate_config.json -outd ./vaggregate_output -outt all -db 1000G:~/references/human/1000_genomes/chrm_1000Genomes.20130502.genotypes.vcf.gz -db dbsnp:~/references/human/dbsnp/common_all.hg19.sorted.leftalign.vcf.gz

### JSON config file

`vagg_config.py` produces a JSON-formatted configuration file embodying the selected options for the subsequent Vaggregate run. The configuration could be edited manually (e.g., to tweak a database name or path) or programmatically (e.g., if `vagg_config.py`'s guesses about sample IDs were incomplete) at this stage.

Alternatively, `vagg_config.py -ex` produces a syntactically valid example JSON file for editing.

Producing a configuration file is intended to facilitate the following:
* Consistency between runs
* Documentation of settings
* Easier use with dozens to thousands of input files
 

Variant Aggregation!
--------------------------

Execution: `vagg.py <config.json>`

Vaggregate is executed by launching the main `vagg.py` script, passing as a single parameter the name of the previously generated/edited JSON file. 

Output files of the specified type are placed in the output directory specified during configuration.


Output File Formats
-------------------
Output types are specified at the time of configuration. The user may select any number and combination of output types from the list below.  

**all**
Execute all output types

**counts**
Print counts of mutations per feature. Output: `counts.txt`

**txt**
Print all information about each variant, with one-per-row, irrespective of how many samples in which it appears. Useful for variant-centric projects. Identical to xls in layout. Output: `variant_details.txt`

**longtxt**
Similar to txt above, but writes each instance of a variant to a new row. Each variant is written once per source file, instead of combining recurrent variations into 1 unique row. Identical to longxls in layout. Output: `long_variant_details.txt`

**xls**
Print all information about each variant, with one-per-row, irrespective of how many samples in which it appears. Useful for variant-centric projects. Identical to txt in layout. Output: `variant_details.xls/xlsx`

**longxls**
Similar to xls above, but writes each instance of a variant to a new row. Each variant is written once per source file, instead of combining recurrent variations into 1 unique row. Identical to longtxt in layout. Output: `long_variant_details.xls/xlsx`

_NB_: The XLS format has a hard limit of 2^16 rows; in long record format, a moderate sized study could exceed this (2,000 total variants/sample * 32 samples = 65,536 rows). Vaggregate can use Python's `xlwt` module to write .xls format, but it is preferrable to have `XlsxWriter` or `openPyxl` installed for .xlsx support.

**bed**
Print bed file of the variant locations Output: `variant_locations.bed`

**vcf**
Print vcf file of the variant locations, features, depths, and variant frequencies. Output: `variant_locations.vcf`

**featXsamp**
Print table of mutation counts per feature per sample. Samples are in columns, while features are in rows. The count of unique mutations per sample per feature are the table values. This output is useful for examining patterns in variation across samples, for example, to look at combinatoric mutation status for selected recurrently mutated genes. This output could be used directly to make a heatmap. Output: `feature_by_sample.txt`

**featmutXsamp**
Print table of mutations per sample. Unlike **featXsamp**, this differentiates among different variants within the same features. For example, in acute leukemia, the functional effect of mutations in DNMT3A depends on whether it is an R882 mutation or non-R882 mutation. As before, samples are in columns, with features in rows. However, rows 2-4 contain information about chromosome, position, ref, and alt. The table values are boolean: 1 for present mutation, 0 for missing mutation. This output could be used directly or with appropriate filtering to make an Oncoprint. Output: `feature_and_mutation_by_sample.txt`


Known Issues
============
The --union feature will behave inappropriately when genomic feature names are duplicated on the same contig. For example, if gene "ABC" is duplicated on the beginning and the end of chromosome 1, the feature bin for gene "ABC" will cover the whole contig (from the beginning of the first copy of "ABC", to the end of the last copy). Users may select another feature type, such as gene_id, which is unique to every copy of a gene. Otherwise, users may run the included python script [detect_union_bin_errors.py] to detect potential bin errors. It accepts a feature_type, a GTF/GFF annotation, and an output directory. The output is a text file list of feature names likely to cause large bin errors. Place this text document into the working directory where Vaggregate will be executed. Vaggregate will automatically search for the text file by name ['union_incompatible_genes.txt'] in the current directory. 
    
    python ./detect_union_bin_errors.py -o ~/projects/vaggregate -g ~/references/human/gencode/gencode.v19.annotation.gtf -f gene_name

There is an issue when a variant file presents a contig that the pickled (archived) annotation does not have. This will throw a warning that shows how many contigs were unknown, and how many mutations were encountered on these contigs. The solution is to disable the archive feature by omitting the `-a` or `--archive_directory` option. This will permit the unknown contig in output, but all mutations on the unknown contig will be shown as having no feature. 

    *** WARNING: 18 Contigs and 39 mutations are in areas unknown to the genomic array of sets. If using --fast, perhaps try again without it. *** 

The VCF files need to have columns #CHROM, POS … etc. The configuration script checks each VCF file for proper columns and will print a warning if any are missing or wrong. However, it does not halt execution and will include any malformed column VCF files and attempt to process them regardless. The main script may finish execution with the malformed VCF, but the output may be perturbed or useless.

    File "vaggregate/inputs.py", in parse_VarScan
        position = int(row[fieldId['POS']])
    KeyError: 'POS'

Users may not supply vcf files that have inconsistent 'effect' and/or 'functional consequence' for the same variant. Presumably, if the variant has the same location and reference and alternate allele, the effect and functional consequences would be predicted to be the same. The problem lies in collapsing mutations in the `variant_details` output type(s). This issue may arise when different platforms or pipelines are used for samples containing a common variant within a single run of Vaggregate. If this is found to be more common than expected it will be worked around.

Bug Reports and Issue Tracking
==============================

Check the issue tracker at the github repository. Please report bugs and request new features there for better tracking.

Contact
=======
James S. Blachly, MD  
james.blachly@osumc.edu

